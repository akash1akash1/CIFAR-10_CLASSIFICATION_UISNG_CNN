# -*- coding: utf-8 -*-
"""M22MA007_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cIk5hGZFiWStVR8nkGVx86ntUstNl3FJ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt



transform = transforms.Compose([
    transforms.RandomRotation(degrees=10), #10 means maximum roration angle by which image can be rotated (data augmentation technique)
    transforms.ToTensor(), # converts pixel values from  0-255 to 0-1 and converts numpy to tensors 
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #these are the mean and sd values of 3 colours
])

class GaussianNoise(object):
    def __init__(self, mean=0., std=1.):
        self.mean = mean
        self.std = std

    def __call__(self, tensor):
        return tensor + torch.randn(tensor.size()) * self.std + self.mean

    def __repr__(self):
        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)

transform.transforms.append(GaussianNoise(mean=0, std=0.1))

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)



# #Get the first 5 images from the train set
# images, labels = zip(*[trainset[i] for i in range(5)])

# # Create a grid of the original images
# fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(12, 3))
# for i in range(5):
#     axs[i].imshow(images[i].permute(1, 2, 0))  # Transpose the tensor to (height, width, channels)
#     axs[i].axis('off')
#     axs[i].set_title('Original')

# # Apply the Gaussian noise transform to the images
# images_noise = [transform.transforms[-1](image) for image in images]

# # Create a grid of the noisy images
# fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(12, 3))
# for i in range(5):
#     axs[i].imshow(images_noise[i].permute(1, 2, 0))
#     axs[i].axis('off')
#     axs[i].set_title('With Gaussian noise')

# plt.show()



target_classes = [1, 3, 5, 7, 9]
train_data = []
train_targets = []
for i, target in enumerate(train_dataset.targets):
    if target in target_classes:
        train_targets.append(target)
        train_data.append(train_dataset.data[i])
train_dataset.targets = train_targets
train_dataset.data = train_data

test_data = []
test_targets = []
for i, target in enumerate(test_dataset.targets):
    if target in target_classes:
        test_targets.append(target)
        test_data.append(test_dataset.data[i])
test_dataset.targets = test_targets
test_dataset.data = test_data

# Create data loaders
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)

dataiter = iter(train_loader)
# images, labels = dataiter.next()
for images,labels in dataiter:
  print(images.shape)
  break

# Define the CNN model with 6 col layers and 1 pool layer
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()


        #output size after convolution filter is applied is (w-f+2p)/s +1 w =sidth(32),f=size of kernel(filter...3),p=padding(1),s=striding(1)
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, padding=1)  #input shape is [batch=100,channels=3,size = 32*32] and 12 filters
        #new shape = [100,12,32,32]
        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, padding=1)  
        #new shape = [100,24,32,32]
        self.conv3 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, padding=1)
        #new shape = [100,48,16,16]
        self.conv4 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, padding=1)
        #new shape = [100,96,16,16]
        self.conv5 = nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, padding=1)
        #new shape = [100,192,8,8]
        self.conv6 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1) #total 6 convolution layers
        #new shape = [100,384,8,8]
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #1 pool layer just a transformation process (6conv so 6 layers in maxpool)
        self.fc1 = nn.Linear(in_features=384 * 4 * 4, out_features=512) #flattening the features we got in maxpool
        self.fc2 = nn.Linear(in_features=512, out_features=10)

    def forward(self, x):
        x = nn.functional.relu(self.conv1(x))
        x = nn.functional.relu(self.conv2(x))
        x = self.pool(nn.functional.relu(self.conv3(x)))
        x = nn.functional.relu(self.conv4(x))
        x = self.pool(nn.functional.relu(self.conv5(x)))
        x = self.pool(nn.functional.relu(self.conv6(x)))
        x = x.view(-1, 384 * 4 * 4)
        x = nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = CNN().to('cuda' if torch.cuda.is_available() else 'cpu')

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
train_losses = []
for epoch in range(10):
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to('cuda'), data[1].to('cuda')
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 100 == 99:
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))
            train_losses.append(running_loss / 100)
            running_loss = 0.0
    # Print loss after every epoch
    print(f"Epoch {epoch+1} loss: {train_losses[-1]:.3f}")

# Plot training loss vs epoch
plt.plot(train_losses)
plt.xlabel('Epoch')
plt.ylabel('Training Loss')
plt.title('Training Loss vs Epoch')
plt.show()

print('Finished Training')

# Evaluate the model on the testing data
correct = 0
total = 0
with torch.no_grad():
  for data in test_loader:
    images, labels = data[0].to('cuda'), data[1].to('cuda')
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

      # Print the accuracy and loss for each epoch
print('Epoch %d, Train Loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))
print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))

# Plot the accuracy and loss over time
import matplotlib.pyplot as plt
import numpy as np

train_losses = []
test_losses = []
train_accuracy = []
test_accuracy = []

# Calculate the training and testing loss and accuracy for each epoch
for epoch in range(10):
    train_loss = 0.0
    test_loss = 0.0
    correct_train = 0
    correct_test = 0
    total_train = 0
    total_test = 0

    # Calculate the training loss and accuracy
    model.eval()
    with torch.no_grad():
        for data in train_loader:
            images, labels = data[0].to('cuda'), data[1].to('cuda')
            outputs = model(images)
            loss = criterion(outputs, labels)
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()

    # Calculate the testing loss and accuracy
    with torch.no_grad():
        for data in test_loader:
            images, labels = data[0].to('cuda'), data[1].to('cuda')
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()

    train_losses.append(train_loss / len(train_loader))
    test_losses.append(test_loss / len(test_loader))
    train_accuracy.append(100 * correct_train / total_train)
    test_accuracy.append(100 * correct_test / total_test)

# Plot the training and testing loss over time
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Testing Loss')
plt.legend()
plt.show()

# Plot the training and testing accuracy over time
plt.plot(train_accuracy, label='Training Accuracy')
plt.plot(test_accuracy, label='Testing Accuracy')
plt.legend()
plt.show()